[{"title":"初探无后端静态博客自动化部署方案","date":"2020-02-14T14:10:12.000Z","url":"/post/automated-deployment-of-serverless-static-blog/","tags":["Hexo","自动化","部署","Github Actions","Netlify","Travis CI"],"categories":["笔记本"],"content":" 本文首发于「少数派」。 与 Hexo 同样，Hugo, Vuepress 等都属于「无后端静态博客」阵容。而部署流程也不外乎在本地利用环境生成静态资源并上传网页目录，托管于不同服务。 而如果我们希望能够在一台陌生设备上迅速「恢复状态」，则需要： 利用本地搭建好的环境生成 网页目录 并上传部署 同步 博客源码 至云端方便异地协作 好像也不麻烦？ 但是在每一台设备上都绕不过恼人的环境配置。 更何况，能一步做好的，为什么要两步？！ 期望我们设想以下场景： 使用 GitHub 私有仓库 blog 存放博客源码 使用 GitHub 公共仓库 website 存放网页目录 我们的预期是，将网站更新后的源码推送到 blog 时，能够自动检测更新并且重新部署到 website 中。 也就是说，只有红色部分是需要我们手动完成的，其余的（蓝色部分）则交给自动化。 好在，现在已经有比较成熟的解决方案。例如即将提到的：Netlify, GitHub Actions, Travis CI 等。 Netlify 可能是目前最简单的自动化部署方案了。 Netlify 是一家位于旧金山的云计算公司，为静态网站提供托管服务。同时拥有免费和付费的服务可供选取，免费额度目前为 300 分钟每月的计算时长限制和 100 GB 每月的流量限制，超出都会索取一定费用。关于不同套餐之间的功能和限制可以参考 官方页面 。 计算资源方面与 GitHub Action 相比有点「节约」，一次更新大概是需要 1 分钟左右的部署，一个月约 300 次的更新也还算充裕。如果需要调试页面还是建议就放在本地执行。 部署操作Netlify 部署的流程也很简单，我们详细的来看一下。 首先自然是使用 GitHub 账号登陆，然后来到主页，点击 New site from Git 紧接着选择从 GitHub 获取，会让你授权，并不需要将所有 repositories 都授权给 Netlify，即便是私有仓库也没问题。 注意这里，建议只将需要部署的仓库授权给 Netlify 而非全部仓库： 之后就可以配置部署的设置了。需要注意：Build command 指的是构建，也就是生成网站源码所使用的命令；而 Publish diretory 则为生成的网页目录的位置。此外我们还可以调整默认部署的分支和拥有者（免费版暂不支持多账号协作）。 点击 Deploy site ，稍微等待一会你的网站就部署好了。可以前往设置更改 site-name ，默认域名为 site-name.netlify.com ，你也可以绑定自己的域名，Netlify 使用 Let’s Encrypt 提供的免费证书进行 HTTPS 部署。 自动更新待上述步骤完成，不出意料我们已经可以访问网站了。 现在尝试一下添加 post，将其直接推送到 Blog 仓库中。 再回到 Netlify 页面，发现 Netlify 已经成功监测到 repository 变动并自动开始了新的部署。不一会，就已看到新的页面上线了。 小结Netlify 凭借足够简易的操作逻辑，以及可观的免费额度，确实值得考虑。 另外， Netlify 提供全球 CDN 支持，即便是免费账户也可以享受更快的访问速度，这一点较 GitHub Page 在体验上确实加分不少。 GitHub Actions 享受慷慨资源的同时，意味着一定的代码能力。 GitHub Actions 允许使用者构建持续集成与持续部署管道来测试、发布、搭建软件而无需借助第三方平台。持续集成由许多操作组成，如抓取代码、运行测试、发布等，GitHub 将其统称为 Actions。 借助这个特性，我们也可以让 GitHub Actions 来帮助我们部署网页。 GitHub 继续维系大厂作风，免费额度可以说是「慷慨」。6 小时的连续计算时长限制，而总时长则不设限。这点可以说是碾压 Netlify 的免费额度。 而在 GitHub Action 里，有这样几个基本的「单位」： workflow：一个持续集成的过程，就是一个 workflow 。 jobs：一个 workflow 可以同时完成多个 jobs，每个 job 独立完成，互不干扰。 steps：每个 job 可以包含多个 steps，一步步完成。 actons：每个 step 可以执行多个 action 。action 可以理解为一条条命令，是 GitHub Actions 中最小的单位。 且 GitHub Actions 为每个 Job 提供一个独立的虚拟环境运行，都拥有相同的硬件资源： 2 核 CPU 7 GB RAM 内存 14 GB SSD 硬盘 重新定义良心…… 关于 限制 和 收费 可以参考 GitHub Actions 的 Wiki 。 部署操作废话不多说，赶紧看看如何使用。 首先我们要生成一个 SSH 密钥，方便 GitHub Action 上传网页目录到我们的 repository 。 将公钥添加到存放网页目录的 GitHub 账号「Settings - SSH and GPG keys」内；将私钥添加到你博客源码仓库的「Settings - Secret」内，起一个名字，例如我让他叫 HEXO_DEPLOY_KEY 。 之后就是新建一个 Workflow。点击 GitHub 仓库控制栏中的 Actions，选择新建一个，并将下面的代码替换掉原来的代码。 这份代码究竟在做什么： 最上方 name 是整个 workflow 的名字；紧接着的 on 参数指的是触发调节，比如我们这里使用 push 来触发，每次监测到仓库被 push 了就运行此 workflow。 接下来就是 jobs 。我创建一个名为 build 的 job，runs-no（运行在）最新版的 ubuntu 系统里。 里面的 steps（步骤）有：checkout 引入调用自身仓库的插件；Node.js envs 调用 Node.js 搭建环境；Hexo deploy 网页部署。 将代码中的部分信息更新为自己的，就可以尝试更新 push 一下了！ 小结最「原生」的支持，实在慷慨的计算资源，（几乎）可以忽略的限制。这些，都或许是你选择 GitHub Actions 的理由。 虽说是持续集成，实则是用完即毁。所以每次都是崭新的环境，需要重新安装各项依赖。只不过这些都不用本地执行，第一次配置好了之后也完全不用再操心。 每次 push 完后需要大概十几秒的等待才能部署（个人感觉还是快于 Netlify），debug 也还是建议先在本地调试再上传。 至于 GitHub Actions 的使用细节还请参考 官方文档 。 Travis CI和 GitHub Actions 类似，Travis CI 也提供持续集成服务。同时 Travis CI 还是同类型服务商中市场份额最高的，在 GitHub Actions 诞生之前一直是最受欢迎的持续集成服务商（之后或许也是）。 目前 Travis CI 只面向 GitHub 提供服务，也就是说只有将代码托管到 GitHub 仓库才能享受到 Travis CI 提供的服务。 GitHub Actions 所有 workflow 都是以文件的形式保存的，Travis CI 也是如此。Travis CI 会根据根目录下的 .travis.yml 来执行相应工作流。 一个 Travis 完整的工作流程包括： language（设置环境） before_install install before_script script aftersuccess or afterfailure [OPTIONAL] before_deploy [OPTIONAL] deploy [OPTIONAL] after_deploy after_script 都是使用命令执行，只不过不同流程中对于命令之间的逻辑关系处理的不太一样。 如 install 类中有： 在 command 1 失败后整个构建就会停下来，command 2 也就不再执行。 而对于 script 一类的： 就算 command 1 失败，command 2 也会继续执行。但是整个构建状态还是会返回失败。 部署步骤我们前往 Travis CI 官网 使用 GitHub 账号登陆，根据提示授权。 出于安全考量，GitHub 肯定不会允许一个陌生容器将内容推送到自己的仓库中。我们需要使用一种特殊的手段给 Travis CI 授权——Access Token 。Access Token 可以理解为一个口令，当 Travis CI 使用这个口令和 GitHub 对接的时候，GitHub 就能知道是否应该给予 Travis CI 权限以及应开放哪些权限。 在 GitHub 账号中「Settings - Developer settings - Personal access tokens」中新建一个 token 。注意这里的 token 应考虑一下是否需要保存下来，token 只会出现一次！ 之后回到 Travis CI，选择添加仓库，将博客源码的仓库对应按钮点亮，并点击后面的 settings 进入更深入的设置。 这里的 Environment Variables ，类似 GitHub 中的 secret ，可以保存一些不便公开的参数，如 Access Token 等，方便仓库开源和后续的调用。如果不想公开 GitHub 的用户名和邮箱，也可以在放入这里。 然后是配置 .travis.yml 文件： 代码也不难理解。最上方为设置在 Node.js 环境下运行，并且设置为获取最新版本的 Node.js 。由于 node_modules 目录体积较大且后期维护时修改频率很低，所以我们将其缓存以加快更新速度。再往下就是正常的安装和部署命令了。 小结Travis CI 老牌且强大，可就我短时间体验来看感觉不如 GitHub Actions 来的那般方便。而且 Travis CI 仅支持公开的仓库，如果想在私有仓库上也启用则需要购买 商业版（前 100 次试用免费，价格略贵）。也算是一种方案，只是已经不是很推荐了。 最后Netlify 适合不愿在配置上花费太多功夫的用户，我在这里也近乎将其部署流程每一步都提及了。确实，放到一起来看 Netlify 学习成本几乎为零，任何人都能立马上手。 GitHub Actions 和 Travis CI 则需要一定的代码能力（一点点就好），能够理解 Workflow 便能很快的构建好自己的工作流。 如果再进一步，设置一个十分简单的推送脚本（go.sh）： 那一切的一切都只需要 sh go.sh &quot;commit message&quot; 一行解决。 但这些方案终究只是减少你在重复行为上花费的时间，让你能够集中精力在更有意义的事情上。最重要的还是赶紧把你的 Ideas 记下来、说出来，让更多的人了解你的想法。希望你能有所收获！ (Ended, thanks for reading! )"},{"title":"搭建一个在线 IDE，Jupyter Notebook 帮你快速构建","date":"2020-02-09T08:46:17.000Z","url":"/post/build-an-online-ide-by-jupyter-notebook/","tags":["Nginx","Web","Jupyter Notebook","IDE"],"categories":["笔记本"],"content":" 本文同步载于 少数派 ，部分 markdown 语法在该页面渲染失败。 其实本文和以前 那篇文章 操作十分类似，这次只是稍微解释的详细一点（废话多一点）。 以下是原文。 过年探亲，总会是一件很惬意的事情。但是碰巧不巧，这年来了点状况，各路返工返校全部延后。看着呆在家里快成一条死鱼的自己，无奈只有一台手机 / iPad，完全与生产力搭不上边。不急，如果你折腾了我即将介绍的东西，那只要有一个浏览器，就能在任何地方编写、运行代码；如果没有，那你也可以把自己关在家折腾一天，把所有坑全部踩一遍，这样减少人口流动，也算是对抗疫做些贡献。 Jupyter Notebook 介绍回到正题。 什么是 IDE？IDE 全称是集成开发环境 (Integrated Development Environment) ，是一种辅助开发人员的工具。在该工具内可以编辑源代码文件、并编译打包成可执行的程序。一个 IDE 通常包括：编程语言编辑器、自动构建工具、调试器，有的还包含编译器 / 解释器 ^1。 所以，目标人群很清晰。如果你完全对编程不感兴趣、不想「手玩」几个源代码的话，你可以关闭本页面了。 OK，接下来再来看 Jupyter Notebook 。Jupyter Notebook 的前身是 iPython Notebook ，而在 2014 年 Jupyter 正式从 iPython 中衍生出来，成为一个独立的项目，为数十种编程语言的交互式计算提供开源软件、开放标准和服务。Juypter Notebook 则是一个基于 Web 端的交互式计算环境，用于创建 Jupyter Notebook 文档 (.ipynb) ，由一个个单元格组成，单元格可以包含代码、Markdown 文本、数学、图标和富媒体 ^2。看得出来，在这样的支持下，我们可以一边编写、运行代码，一边用 Markdown 做注释、记笔记，十分方便。 Jupyter Notebook 上手既然是要运行在网页端，一台云服务器肯定是不能缺席的。至于云服务器的购买建议就不在本文的探讨范围内了，大家根据自身条件和需求判断。 到这里我默认大家已经购买好、并通过 SSH 连接上了远程服务器。 由于我正在学习 Python ，就拿这门语言的配置举例。其他语言也遵循 环境 - 工具配置 的主流程，会在文末是稍微提一下。 开发环境安装众所周知，Python 通过模块化特性，避免了许多「造轮子」等行为，提升了编程效率。而实际使用中，难免需要调用各种第三方模块。这时我们可以通过一个 Package 来一次性安装许多常用模块，Anaconda 就是这样一个基于 Python 的数据处理和科学计算平台，它已经内置了许多非常有用的第三方库。我们可以选择直接安装 Anaconda 来跳过安装许多模块、依赖的步骤。但是，Anaconda 过于强大的同时避免不了过于庞大，所以我选取的是 Miniconda ，可以理解为 Anaconda 的精简版，去除了许多也许有用但并不是非常常用的模块，体积也大大缩减。 我们使用官方提供的一键脚本安装： 然后是安装 IPython 和 Jupyter ： 工具配置 执行上述命令来在 ~/.jupyter 目录下创建一个 jupyter_notebook_config.py 的配置文件。 用编辑器打开这个配置文件。太长？没关系，我们只需要关注几个地方，其他使用默认配置即可。 c.NotebookApp.port 这个是服务将要运行在的本地端口，填写一个还没有被服务占用的端口。然后 IP 默认是本机 IP (localhost) ，后面也是通过 Nginx 端口映射到本地端口，所以不用管。 c.NotebookApp.allow_origin 因为我们需要外网访问，所以请设置为允许任意 (*) 即 c.NotebookApp.allow_origin = &#39;*&#39; 。 c.NotebookApp.open_browser 由于远程服务器大多不安装图形界面，自然也不会有浏览器，这里要设置为 False 。这样每次启动服务的时候就不会尝试打开浏览器了，也就不会报错（找不到浏览器）。 c.NotebookApp.notebook_dir 这里设置 Notebook 的文件目录，默认是家目录 (~) ，可以设置为一个专门存放代码的目录。 c.NotebookApp.allow_root 出于安全考量，Jupyter Notebook 默认禁止了在 root 用户下运行，也不建议这么做。你可以新建一个账户来运行 Jupyter Notebook ，或者将这里设为 True ，这样就允许 root 用户运行了。 单独拎出来提一下关于密码。由于这项服务是要暴露在公网的，你或许也不想任何人都可以使用你的计算资源，或者查看、修改你的源码文件，这时可以给 Jupyter Notebook 设置一个密码。 执行上述命令，根据提示输入你想设置的密码。然后将最后生成的以 sha1 开头的文本保存下来，这是你的密码经过散列函数加密后得到的内容。 接着在配置文件中找到这两行： 经过一点点配置后，在终端中执行 jupyter notebook 就可以启动服务了。 Nginx 端口映射到上一步为止，我们已经可以通过 {服务器 ip}:{端口号} 的形式访问了（如果开启了防火墙则需要允许特定端口访问），但使用这种形式访问不如用域名访问那般友好，而且不支持 HTTPS 也会带来安全隐患。 这时我们可以借助 Nginx 反向代理 将域名映射到本机制定端口。Nginx 是一个异步框架的网页服务器，高效、并发能力强。我们先来安装 Nginx ，以 CentOS 为例： 确认开启无误后，我们修改 Nginx 配置文件，让其监听指定域名并重定向到本机 Jupyter Notebook 的服务端口。 先 upstream 声明： 这样后面就可以使用  统一调用 Jupyter Notebook 服务地址了。 然后是 server 部分，假设我们使用 jupyter.domain.com 来访问 Jupyter Notebook 。 第二、第三行为监听端口，HTTP 为 80 端口，HTTPS 为 443 端口 第四行为希望监听到的域名 13 - 19 行为 SSL 证书设置，需要注意13 - 14 行为你的证书路径，需要是绝对路径 后面则是转发相关的配置 再次终端输入 jupyter notebook 运行服务，在浏览器中输入域名，不出意料就能看到输入密码的页面了。 保持后台运行现在程序一直是占用着终端的，而且如果关闭终端连接就会中断服务。我们需要让 Jupyter Notebook 静静地呆在后台运行。 先创建 jupyter.log 日志文件记录运行状态。 然后执行命令： 其中 nohub 表示 no hang up 不挂起，默默在后台运行，并将输出重载到日志文件中。 此时如果要中止程序，则需要 ps -A 检查所有进程 pid，然后执行 kill {pid} 来中止服务。 其他语言配置如果你学习的不是 Python 语言，但只要是在 这个页面 提到过的语言，都是支持的（Jupyter 的版本达到要求的前提下）。在安装好 conda 后，可以使用命令： 来安装其他 kernel。 比如拿 C++ 举例，只需要执行： 但是！为了防止某些无法理解的错误发生（如不同环境间的冲突或某些库不兼容），请考虑新建一个虚拟环境，然后在里面单独安装。如创建一个名为 cling 的虚拟环境，当然也可以是别的： 如果未出错则会显示目前已经（在独立环境中和主环境中）安装的 kernel ： 这时候到 Web 端，新建操作就会可以选择多种语言了。 后全文到这里就要暂告一段落了。我们讨论了： Jupyter Notebook 的安装和配置 将 Jupyter Notebook 借助 Nginx 得以在公网访问 通过 Conda 管理多语言配置 限于篇幅，这次重点介绍搭建的过程，而对于许多工具背后的设计理念和哲学并没有深究。 回顾 Jupyter Notebook，Web 端、方便、交互式、Markdown 、多元……，这些特点一直伴随着它。可是，你真的需要它吗？ 需要明确的是，对于工具的探索终究是为了更好地服务于你，好工具的定义对于每个人都是不一样的。这款工具能够满足你的需求，能否提升效率，只有你自己说了算。而过度热忱于追求工具，淡化了任务本身，显然是一种本末倒置的行为。 所以，你会来玩玩这个吗？ "},{"title":"V2ray + CDN 稳定看世界","date":"2020-02-05T02:17:01.000Z","url":"/outlook/get-a-stable-outlook-through-v2ray-and-cdn/","tags":["V2ray","Socks","扶梯"],"categories":["分享集"],"content":"最近墙一直「居高不下」，许多扶梯提供商已经坚持不住。但有些人还真是有访问外网需求，包括笔者自己。这里记录下一种（或许）能坚持更久的代理方式，尽可能维持大家的上网体验。顺便免费分享几个笔者自己搭建的节点，直到这段时期过去。 如果你想更深入地了解「代理」，可以看我之前写的一片文章「Proxy Server | 正向代理与反向代理」。这里就着重记录搭建方法。 V2ray 简介V2ray 是 Project V. 团队开发的内核，使用自实现的 Vmess 协议和 mKCP 协议，和 Shadowsocks 一样是一种新型代理方式。但是更进一步，V2ray 支持更多的协议，更多的混淆。也让这种代理（某种程度上）能活得更久。 但是我还是要来辟谣：并不是上了 V2ray 就真的能够骗过墙的眼睛，只不过能拖延一下而已，该做什么就做什么，不要整天想着怎么安全安全，规范自己的行为就好了。还有就是什么 SS 已死 的说法，稍微动动脑子好吗？就从我自己使用的经历来看，不论是机场还是自建主流都还是 Shadowsocks ，为什么？目前 V2ray 还是比较臃肿，占用大。我在同一台 VPS 上同是搭建了 SS 和V2ray，开启谷歌官方 BBR 拥堵控制算法，大陆南方联通／电信都有，晚上 11:30 ，SS 还能跑 50M，V2ray 只能跑 10M（全部是裸的跑）。而且 V2ray 的软件生态还是远不及 SS 的，客户端体验都不算良好。所以，不要见到 V2ray 就盲吹（当然也不能盲踩），就目前来讲，条件允许的话，我还是更愿意使用 SS。 搭建流程一下操作可能需要一点动手能力，如果不愿折腾的同学可以考虑下 IPLC 专线机场 ，由于专线不过墙特性，非常时期也可用！ VPS 购买首先无论是 SS／V2ray 都是与服务端通过 某种协议 建立隧道连接后通过服务端代理客户端的流量，从而实现上网目的。所以我们要先购买可用的境外服务器。 这里我不是很想推荐，大家按照自己习惯来。如果真的没有经验、或者不想淌主机圈这潭浑水的同学，可以尝试 vultr ，支持微信／支付宝付款，最低配置 5 刀／月，全球 16 个机房，直连推荐日本机房，大陆直连效果挺好，新加坡的机房就一般了，美西也不错。如果有能力注册阿里云国际并绑定支付方式的同学也可以尝试阿里云的机子，阿里新加坡的机房很好，直连大陆延迟都在两位数（70ms 左右），性价比也很高，不差钱也可以上香港的。 但是！由于这篇文章是介绍非常时期的连接，所以我们后面会使用 Cloudflare 提供的免费 CDN ，而应该没有人为了这个购买专业版，所以只有美国 CDN 节点，也建议购买 VPS 的时候选取美国机房，这样甚至比靠近的机房还快一点（回源远了嘛）。 然后就是如果你前往购买的云主机商家的官网并没有被墙的话请关闭代理登录，注册时候邮箱必须是真实有效的，地址可以不用真实的，但是请离你注册时使用的 IP 近一点，以免不必要的麻烦发生，其他信息自己看着办，别太离谱就好（vultr 只用一个邮箱就可以注册）。毕竟还是牵扯到钱的事情，小心为妙。 具体购买方法不想赘述，一般几个朋友日用选最低配置就够了，系统建议选择 CentOS/Debian/Ubuntu ，使用的人多、社区庞大，遇到问题也可以在各种教程、论坛中快速解决。 连接 VPS假设到这里你已经成功拥有了一台了 VPS，主机商家应该回给你发送一个包含 IP 地址和 root 密码的邮件，你也可以登录它们的官网查看。我们要使用 SSH 工具连接 VPS。 Mac 使用自带终端即可，Windows 需要下载工具，如 MobeXterm Xshell 等工具。 笔者使用的是 Mac ，但操作大同小异。 使用 SSH 远程连接 VPS 然后将 root 密码复制到下面的密码框中并回车（不会显示） 建议登录后先更改 root 密码，终端输入即可根据提示修改管理员密码： 安装 V2ray为了一定程度上更抗封锁，我们使用 ws (WebSocker) + tls + CDN 的形式，Cloudflare 提供免费的 CDN ，所以我们只需要提供服务器的费用、域名的费用（可选）和时间成本。 首先安装 V2ray： 如果报错可能是你 VPS 系统没有安装 curl CentOS 安装：yum update -y &amp;&amp; yum install curl -y Debian/Ubuntu 安装：apt-get update -y &amp;&amp; apt-get install curl -y 然后根据提示来，传入协议选择 WebSocket + TLS ，端口不小于 1025 且没有被占用。 填写的域名记得解析到 VPS 的 IP 上，如果你还没有域名，可以考虑： 付费：浅谈国外域名注册商 免费：Freenom 免费域名申请及使用 域名其实不贵，如果要求不高再考虑免费域名，毕竟一个域名可以干许多事情，Namesilo 还提供终身的免费 WhoisGuard 隐私防护。获得域名后将域名托管给 Cloudflare 并打开 CDN 服务。教程 填写好域名后不要自动配置 TLS ，我们后面自己来。至于去广告和安装 SS 自己看，反正我是没有选择，让专业的人做专业的事。 之后让它安装就好，记得最后记录一下配置文件的路径，后面会用到。 安装宝塔面板宝塔面板是一个对新手十分友好的 VPS 运维可视化操作面板。 CentOS ： Debian/Ubuntu : 安装好后登录（记得登录随后修改默认登录密码），安装 Nginx（如果日后还有建站需求也可以安装 LNMP 一绝后患）。 新建网站配置好环境之后就可以新建一个网站。域名填写刚刚配置在 V2ray 的那个域名，由于默认 V2ray 使用 443 端口，所以需要 https ，可以使用 Let’s Encrypt 或者 Clouflare 的免费 SSL 证书。 这里重点介绍下 Cloudflare 的证书申请，前提是你将域名交给 Cloudflare 托管（不交给他你后面怎么它们的 CDN 呢）。 在域名管理页面 SSL/TLS -&gt; Origin Server -&gt; Create Certificate 创建证书，注意保存下来，密匙只会出现一次。 然后从宝塔面板网站 SSL 设置中的其他证书中导入此证书即可。 接着修改配置文件，在合适的地方添加： 你甚至可以添加一个反向代理到正常的网站，让流量看起来更正常。 修改 V2ray 配置在 V2ray 配置文件中（一般在 /etc/v2ray/config.json）定位到 streamSettings ，然后追加成类似下面的配置： 注意在有多个设置时，除了最后一项，其他每一项都要在最后加一个英文半角逗号。 之后执行 v2ray restart 重启即可。 安装 BBRBBR 是谷歌推出的一款拥堵控制算法，可以在基本不增加负载的情况下有效提升连接体验。 使用 v2ray bbr 即可安装 BBR 插件，不推荐其他魔改。 很多人看到BBR不排队的特征后，第一想到的就是 不排队甚好，但稍微在缓存队列里堆点数据包也不错，不然怎么能赢了那些不守规矩的流呢？ 于是乎就出现了各类所谓的 BBR优化，无一例外地都是把Reno/CUBIC那一套算法的 精髓 照搬到BBR，于是BBR就被玩坏了！ … 我退出了 BBR优化队伍，我也不玩了，我潜下心希望能 从数学上证明BBR不排队就是最优的，只要排队就不行，一点队列也不行。本文写作前一天，我得了一些结论。记录这些结论并记录我是怎么想的，就是本文的主要内容。 具体前往： 客户端配置服务端配置完成了，接下来看看客户端。目前有人整理了各平台可用的客户端 链接地址 。 可以在 VPS 中使用 v2ray url 或者 v2ray qr 显示节点的链接或者二维码。 但是导入的时候笔者遇到了一个问题，就是即便修改了 V2ray 配置文件并且重启后，路径仍为默认路经 / ，所以导入到客户端的时候需要手动修改为你设置的路径，就可以正常连接。 节点分享真的有紧急需求却无从连接？这里提供博主自建和收集的几个免费节点供大家使用。请不要在任何场合分享，仅供个人学习使用，请勿作出违反你所在地区及服务器所在地区法律法规的行为，请勿用来下载侵权内容等一切不道德行为。 不是不限流量的 VPS ，所以连不上可能是没流量了，套用了 CDN 。如果有需求还是建议上付费机场，有服务保障，有售后。 "},{"title":"Proxy Server | 正向代理与反向代理","date":"2020-02-02T17:38:36.000Z","url":"/post/proxy-and-reverse-proxy/","tags":["代理","Proxy","反向代理","Nginx"],"categories":["技术向"],"content":"看到这里的同学应该对「代理」并不陌生。无论是特别的上网技能还是 Nginx 映射本地端口，都离不开代理的特效。 这次，让我们再一次看看：代理，究竟是如何运作的。并重点介绍下可能更陌生一点的「反向代理」，我们可以用反向代理干什么。 What’s 「Proxy」 ？无论正向代理还是反向代理，都是「代理」（废话？） 代理就像一个中转站，服务端与客户端之间的交流交给代理在中间代理。客户端想访问服务端，并不直接向服务端发出请求，而是向代理发出，然后让代理转交给服务端；同样的，服务端返回数据，并不是直接发回给客户端，而是发给代理，再让代理交还给客户端。所有客户端和服务端之间的流量都会由代理来转发。 好像把事情变麻烦了？不急，它自有用处。 Forward Proxy | 正向代理正向代理工作原理在正向代理时，代理服务器会先和客户端（Client）建立连接，然后客户端将某些特定请求或全部网络请求发给代理服务器，代理服务器再拿着请求跑去送给对应的服务端（Server）。同样的，服务端回应这个请求的时候也是先发给代理服务器（毕竟表面上这个请求是代理服务器发出的），然后代理服务器再把回应送回给客户端。 优势从上面介绍的正向代理工作原理来看，代理服务器负责代替客户端发出和接收网络请求，所以表面上好像是代理客户端在发出请求（实际上貌似也是） ，这样给真实的客户端披上一层外套。 不难发现，正向代理可以： 突破访问限制（解锁），比如某些限制了地区使用的资源，我可以用一个当地的代理，让它代理我的流量，骗过服务端。 屏蔽广告，代理服务器可以判断返回的内容，如果是不受欢迎的广告或追踪代码，代理服务器就把它拦下来，不发给服务端。 匿名，可能有很多同学都在使用一个代理，服务端无从知道真实的请求是谁发出的，只知道是由代理转发的。从而保障了一定的匿名性。 Reverse Proxy | 反向代理反向代理工作原理那反向代理又是如何工作的呢？这次代理是替服务端（Server）工作了。 服务端只对外公开代理的地址，所有发送给服务端的请求都会先到代理那里，然后让代理再根据请求分发给相应的服务端；回应的时候也是类似。 优势为什么需要这样的一步呢？其实许多服务器并不是十分顽强，收到过多的请求甚至可能宕机，更不用说要是被攻击了。而套上这一层反向代理，代理服务器可以将请求均衡地分配给服务器组，防止过多请求集中在一台或者几台服务器上，使其负载过大影响服务，这就叫「负载均衡」。同样地，遇到异常流量，代理可以直接拦截下来，而且代理还可以隐藏服务端的真实地址，这都起到了保护服务端的作用。 反向代理不仅可以保护服务器，甚至还可以加速访问！比如代理服务器可以将一些静态资源缓存下来，如果遇到请求，就不用向服务端发送，直接返回资源，更有利于让服务端将算力、带宽集中在加载重要的地方。 这里就不得不提到 CDN 了。CDN 的全称是内容分发网络 (Content Delivery Network 或 Content Distribution Network) ，可以将资源缓存在多台服务器上，访问的时候从最近的服务器中获取，提供高性能的传递且降低骨干网负载。而 CDN 大多也是基于 Nginx 或者 Nginx + SNI 反向代理实现的，所以你也可以将域名指向 CDN 隐藏真实地址。 实践出真知端口映射我在自己的 VPS 上 搭建 Jupyter Notebook 实现 Web 端编写运行 Python 代码。 我配置 Jupyter Notebook 是运行在 localhost:35767 上的。目前我已经将 jupyter.domain.com 解析到该 VPS 地址上了，而从公网访问 VPS 地址都是直接发送给 Nginx 代理上的。所以我们要合理配置 Nginx 使其能够让域名转发到对应服务的端口。 打开你的 Nginx 主配置文件（一般在 /etc/nginx/nginx.conf ，如果你也是使用宝塔的快速安装，那么会在 /www/server/nginx/conf/nginx.conf ） 首先我们定义 upstream 内容： 这样就规定了名为 jupyter 的服务是在本机地址的 35767 端口上运行的，如果访问这个服务就定位过去。之后请求就可以以 http(s)://jupyter 代表 jupyter 的服务端地址，也就是 127.0.0.1:35767 。 然后我们监听 http/https 的请求，分别在 80/443 端口。 这样就实现了让 juypter.domain.com 的请求跳到 juypter 的服务地址，而之前我们已经配置好了该服务地址。 负载均衡端口映射并不能真正体现 upstream 的强大，而负载均衡就不一样了。比如我想将 aria2c.domain.com 请求平均的分配到 6800 和 6999 这两个端口上。 首先定义 upstream ： 之后就只需要监听端口，判断域名是否匹配，然后转发到  即可。 默认两个端口是同级的（权重为 1），你还可以为每个端口设定一个权重，或者根据 IP 分配，根据响应时间分配，等等。 后看，正向代理拓展了客户端上网的姿势，反向代理使服务端更加强大。 但其实，代理能做到的远不止这些，目前已经有了许多玩法。无声无息中为大家提供便利。 限制代理能力的，或许只有人们的脑洞罢了。 (Ended, thanks for reading…)"},{"title":"浅谈「下载」行为","date":"2020-01-30T07:02:54.000Z","url":"/post/what-is-download-actually/","tags":["下载","BT","DHT","磁力链接","HTTP"],"categories":["技术向"],"content":"下载，是我们在互联网中都会接触到事情，每浏览一个页面，打开一个 App ，无不进行着「下载」这样的操作。而今天想讨论的，是纯粹下载本身，把一个文件下载下来。 究竟什么是下载？HTTP 下载和 BT 下载有什么区别？他们是怎么实现的？这也许就是本文想讨论的。 HTTP 下载平时下载一个文件到本地，用 HTTP／FTP 进行文件传输，即与服务器建立连接后，将部分有权限的文件，传输到本地。平时接触到绝大部分下载都是这种行为。 这是最简单的方法，可是有几个显而易见的问题。 所有的资源全部在服务器上，如果服务器出事了，则所有服务全部失效（灾后保障？），所有文件都无法获取。 服务器本身的带宽是有限的。打个比方，我想从服务器下载一个 80 GB 的文件，服务器端带宽是 10Gbps ，我家里的带宽是 500 Mbps，假如我家的带宽十分清真，那我应该在约为 $\\frac{80 \\times 8 \\ Gb}{500 \\times 10^{-3} \\ Gbps} = 1280 \\ s$ 内下载完毕的，但全球许多小伙伴也在下载这个文件，由于我本地的带宽远不比服务器带宽，所以多一些下载也无妨，如同时有 100 个小伙伴在下载，此时就需要 $\\frac{80 \\times 8 \\ Gb}{(10 \\div 100) \\ Gbps} = 6400 \\ s$。但是要是多到一定程度时，比如 100,000 个人同时在下载，那平均每个人能够分到的带宽就只剩 $\\frac{10 \\ Gbps}{100,000} = 0.1 \\ Mbps = 12.5 KB/s$ 则我需要等待超过 $\\frac{80 \\ GB}{12.5 \\times 10^-6 \\ GB/s} = 6.4 \\times 10^6 \\ s$ 。而通常对于一些热门资源，情况还可能会更糟。 尽管如此，还属于「又不是不能用」的范畴。可万一这是敏感资源，导致被有关部门查封，删库，大家都没得下了。 BitTorrent 下载BitTorrent 协议针对上述问题，美国的程序员 布莱姆·科亨 于 2001 年 4 月时发布了一项协议——BitTorrent 协议，是在去中心化网络中的点对点（P2P, point-to-point）文件传输协议。 BitTorrent 协议规定，资源不在由一个中心服务器提供，而是由所有人互相提供，最初的文件发布者将根据发布的文件生成一个 .torrent 文件，即 BT 种子 。BT 种子包含 Tracker 信息和文件信息。Tracker 是你询问应该向谁索要文件块的服务器，Tracker 信息包含该服务器的地址及其配置。文件信息则是根据要分享的文件进行 Bencode 编码后分成每块大小为 $2^k \\ （k \\in N^*）$ 的若干个虚拟文件分块，并将每个块的索引信息和 Hash 校验值保存下来。所以，如果文件是宝藏，则 BT 种子就是藏宝图，带领你获取宝藏。 下载时，先将 BT 种子下载下来，然后连接种子中的 Tracker 服务器，并从 Tracker 服务器中询问到其他下载者的「联系方式」，然后再连接其他下载者，两人互相「摊牌」，交换仅一方拥有的分块。此时文件传输操作仅在两人之间进行，不再需要服务器参与，分散带宽压力。每下载完一个分块还会与 BT 种子中的 Hash 校验值对比，以检验文件准确性。 DHT 技术尽管 BT 包容开放，但弱点也很容易看出来 —— Tracker 服务器。如果 Tracker 服务器被封禁，你将无法找到其他下载者，也从而无法下载。 对此，又有人开发出 DHT 网络技术，可以降低对于 Tracker 的依赖。 DHT 全称为分布式哈希表（Distributed Hash Table），在 DHT 网络中，每个人都是一个小型的路由，储存一部分信息。寻找地址只需要「人传人」即可。 DHT 技术利用 Kademlia 算法建图。在 DHT 网络里，每个节点 (用户) 都有一个独一无二的节点 ID ，由 40 个 16 进制数组成。节点 ID 与文件散列值直接对应。在 DHT 网络中，「距离」定义为两个节点 ID 二进制下按位异或（相同为 0，不同为 1）得到的结果。虽然此「距离」与空间上的距离毫无干系，但是由于异或，此「距离」满足一些几何性质，如 $A \\rightarrow B = B \\rightarrow A$ , $(A \\rightarrow B) + (B \\rightarrow C) \\geq (A \\rightarrow C)$ 等。 在这之前，不论是 HTTP 还是 BT 协议，都离不开 TCP/IP 协议，你真正的地址都还是 IP 地址。但在这里，你的地址、文件地址都彻底变成一段 ID，这个 ID 有 $16^{40} = (2^4)^{40} = 2^{4 \\times 40} = 2^{160}$ 这么多个（宇宙中所有原子的个数大概在 $2^{200}$ 这个量级，所以不用担心不够），也是通过它来避免许多无效的请求。 每个节点都会维护一个路由表，列表存储一些必要信息，列表 ID 或 IP 地址等。建表等时候，该哈希表实际上是一棵完全二叉树（例如左儿子往后添 “0”，右儿子往后添 “1”）叶子结点即为所有 ID 。 从当前根节点二分，将不包含该节点的子树全部放进一个列表，也叫 K 桶中，并维护该桶的「距离」取值区间，且该区间一定是离散铺满的。 且第 $i$ 个桶的从后往前数第 $i$ 位一定与该结点本身的第 $i$ 位不同，而从后往前数的前 $i-1$ 位相同（具体根据哈希树构建的方式）。 任选取一个作为参照，都可以在 $O(logN)$ 的最坏复杂度内找到目标结点。 而且 K 桶是动态更新的，任何结点 ($ \\leq 50\\ % $) 失效不会引起网络功能丧失。 磁力链接有了 DHT 网络，我们就可以通过文件 ID 这样的统一资源名称，通过人传人的方式找到目标文件，中途（可以）完全不需要 Tracker 服务器的协助。 例如下面的 BTIH (BitTorrent Info Hash) 就是磁力链接的一种，除去开头的 magnet, xt, urn, btih 这些标准格式外，后面就是那个 40 位的 16 进制数。 通过这段 ID ，就可以在 DHT 网络中接近目标文件，逐步完成交换。 这样，当你想分享一个文件，只需要分享一个 40 位的数字，足够方便、隐私。 后BT 等去中心化下载模式的不可控性，导致其被垄断信息资源和监控用户行为的个人、组织、企业和政府拒之门外；更何况 HTTP 下载足够傻瓜式，容易操控，是目前最主流的下载方式。 可是回顾一下 HTTP 的弱点： 对主服务器的过度依赖 带宽有限（下载者越多越慢） 面对这种弱点和不同需求，催生了 BitTorrent 协议，它不依赖于中心服务器，随着下载者的增加还会使其速度更快，更加强大。 而一次次的更迭，完善了这样一个抗封锁、抗追踪的下载网络，使得许多内容有机会避开审查。也许服务器可以被攻击、被查封，但种子不行。只要种子还在，那些不存在的资源就会一直活着，永远。"},{"title":"利用 RSSHub 拓展你的 RSS 订阅","date":"2020-01-21T02:12:20.000Z","url":"/post/subscribe-rss-more-variously/","tags":["RSS","RSSHub"],"categories":["便签格"],"content":"上篇文章 介绍了如何搭建自己的 RSS 服务，提升阅读效率。如果遇到一个感兴趣的网站，该如何将其放进自己的 RSS 订阅里呢？ 寻找订阅源相当一部分网站是直接提供了 RSS 地址供大家使用的，RSS 的图标一般会是 一般在网站 顶部／底部／侧边栏 有类似这样的图标，可以直接点击进去，长按复制再导入。 就算网站没有直接把 RSS 图标放出来，链接也一般是放在网站的 /feed 、／rss或者 /atom.xml 之类的，大家可以手动尝试，或者直接将网站首页作为链接添加进订阅源，服务端会自动搜寻几个常用的 RSS 相对地址，找到了就可以直接添加。 比如本站的 RSS 地址为： ，如果你直接将小站的域名输入进去，也可以成功添加。 再或者，可以借助强大的搜索引擎，输入 网站 + RSS 的关键字，或许也能找到。 制作订阅源当绞尽脑汁还是没有找到网站的订阅源时，可能是网站本身没有支持，那我们就利用一些工具给他「造一个」。 借助 RSSHub ，你可以给一些没有 RSS 的网站制作一个订阅源。 RSSHub 是一个开源、简单易用、易于扩展的 RSS 生成器，可以给任何奇奇怪怪的内容生成 RSS 订阅源。RSSHub 借助于开源社区的力量快速发展中，目前已适配数百家网站的上千项内容。 比如我要订阅一个重要的 Telegram 通知频道，我们进入 RSSHub 文档 ，找到 路由 -&gt; 社交媒体 -&gt; Telegram ，发现想订阅 Telegram 频道的路由格式为 /telegram/channel/:username ，这样在确定该频道的 username 后，我就可以以  的链接导入到我的 RSS 服务中了。 再深入的话，RSSHub 还支持内容过滤、条数限制、全文输出等 RSS 服务端可能需要付费才能解锁的功能。 尾声其实我对 RSS 类内容的结尾都在表明一个态度——克制。 无论是选择 RSS 来作为主要的信息获取手段，还是通过自建 RSS 服务做到自己数据完全可控，都无不遵循 理性，克制 两个方面。 RSS 本身就是一种克制的获取方式，仅推送你真正关注的，不会去猜测你想什么然后给你推送一大堆擦边信息。 如果不克制地添加订阅源，导致 RSS 界面反而变得凌乱，无从下手。随便翻一下就对整个订阅源乃至全部文章「标记为已读」。这似乎违背了 Really Simple Syndication 的原则。 既然选择了这条路，就要理性的选择订阅源，看清自己真正需要什么。"},{"title":"用 Tiny Tiny RSS 搭建自己的 RSS 服务端","date":"2020-01-20T07:44:04.000Z","url":"/post/use-tt-rss-to-build-your-own-rss-service/","tags":["自建","RSS","Tiny Tiny RSS"],"categories":["笔记本"],"content":"RSS 曾是互联网上最普遍的信息获取方式。但是，随着各类智能推荐的信息流平台的诞生，2020 的 RSS 似乎早就度过了其黄金时代。 然而，现在的互联网世界越来越多元化，质量也参差不齐。而利用自己的订阅源，避开繁杂的互联网漩涡，高效地浏览所需的信息，似乎更显价值。 为何选择自建 RSSRSS 就像互联网世界中的「通知栏」。一个好的 RSS 服务端才能更好地发挥 RSS 特长。 而笔者认为，一个好的 RSS 服务，应该满足： 排版简洁，可读性高 订阅方便，支持批量操作 (导入／导出) 可自定义过滤规则 放眼目前主流的 RSS 服务，都或多或少的有那么些不足。比如插入广告、不支持过滤规则等。但其实也能理解，毕竟这些服务器还是一笔不小的开支，而过滤规则又需要额外的算力。所以总需要广告／付费来维持。 但是，仅仅为了这点需求，动辄上百元的花费感觉有点不值。再看现在的 VPS ，许多商家都有自己的轻量套餐，一些时期还会推出各种优惠。比如笔者的 VPS 就是在 2020 跨年双旦优惠的时候入手了一台国外主机，13.99 美金一年。 相比之下，笔者之前使用的 Inoreader 高级版就需要 30 美金一年才能解锁过滤器和去广告。这样一来，选择购买 VPS 自建的性价比就凸显了。更何况一台 VPS 能做的还远不止搭建 RSS 这一点。而且自建让数据完全掌握在自己手里，更可控且更安全。 Tiny Tiny RSS目前已经有许多开源的自建 RSS 解决方案。笔者选择的是 Tiny Tiny RSS ，使用广泛功能完善，而且也比较好的满足了笔者的需求。 至于如何安装，主流的有 Docker 镜像安装。而本文介绍一种可视化更好的借助宝塔面板的安装方式。 安装0. 准备环境 Docker CE：后面配置全文爬取的时候会用到 使用 SSH 连接 VPS 安装所需软件包 建立稳定库 安装最新社区即容器化 中途默认 y 通过。如果最后有 060A 61C5 1B55 8A7F 742B 77AA C52F EB6B 621E 9F35 即成功 启动服务并设置开机自启 MySQL 数据库：用于存放 RSS 服务的数据 软件管理 -&gt; 运行环境 安装 MySQL 和 PHP (v5.6 以上) P.S. 建议初次运行宝塔面板的时候直接一键安装 LNMP 安装 fileinfo 兼容插件：由于 MySQL 与高版本 PHP 有兼容性问题，所以需要在 软件管理 -&gt; PHP -&gt; 设置 -&gt; 安装扩展 处安装 fileinfo 至此环境部分全部准备完毕。 1. 新建一个网站点击 网站 -&gt; 添加站点 输入一个指向主机 IP 的域名 (且没被其他网站占用)，在数据库处选择创建 MySQL 数据库，并且选择你安装的 PHP 版本。 确认无误后点击提交。 2. 上传 tt-rss 的包前往 官方 Git 地址 下载最新镜像。 定位到刚刚创建网站的根目录，一般是 /www/wwwroot/domain ，删除原来的文件，上传镜像、解压，然后将解压出来的文件夹里面的内容全选剪贴到网站根目录，再把压缩文件和文件夹删除。 最后根目录大概是这个模样： 3. 给予网站根目录适当权限如果使用默认权限，在后面安装的时候可能会报错失败。我们提前先给好所需的权限。 使用 SSH 连接 VPS 定位到网站根目录： 给予权限： 这样下来后期就几乎不会再出错。 4. 打开网址，安装初次打开网址，会跳转安装页面。 Datebase type：数据库类型，选择 MySQL Username：用户名，使用数据库的用户名，在点击右侧数据库选项中可以查看 Password：数据库密码，在右侧数据库选项中可以查看，也可点击后方按钮直接复制 Host name：直接 localhost 即可 Port：端口，填默认的 3306 然后点击下方测试配置 (Test configuration) ，检查是否正确。 之后会生成 config.php 文件，点击 Save configuration 保存。 然后就可以键入 domain 打开网址，默认账户：admin，默认密码：password 初次使用更改账户／密码登录后，请立刻更改密码。 右上角 -&gt; 偏好设置 (Preferences) -&gt; 用户 (User) 点击 admin 便可修改密码，修改后需要重新登录。 建议平时使用新添一个 User 账户，但给予的是普通用户权限。 Preferences 基本配置在 Preferences 偏好设置 里，还有许多配置需要注意。 这里可以设置语言、时区 (默认都是智能选取) ，以及主题，是否允许 API 登陆此账号 (使用第三方客户端时需要打开) 。 由于 VPS 的空间有限，所以建议清除一定时期以前的旧文章。至于是否清除未读文章，看大家的使用习惯。 Tiny Tiny RSS 默认两栏样式，点击标题以后在下方展开内容。关闭 合并模式 后变为三栏式布局。 Feeds 订阅源设置在 Feeds 可以管理订阅 (添加／删除／修改／分类) ；在 OPML 对订阅批量批量操作 (导入／导出) 。 如果以前使用其他 RSS 服务，可以在原服务端处批量导出称 OPML 或者 XML，然后进入 Feeds -&gt; OPML 处相应导入即可无痛迁移。 你甚至可以对单独订阅源设置名称、更新频率，使用的插件等。 Filter 过滤器过滤器可能是我转移到自建 RSS 的一个重要原因，有了这个帮助就可以更高效地处理大量内容。 Tiny Tiny RSS 的过滤器分为 匹配 和 操作 两个环节。如果满足 “匹配” ，就执行 “操作” 。点击 Create filter 创建过滤器 创建新的过滤规则，Caption 标题 为规则的名称，Match 匹配 为匹配规则，而 Apply actions 应用操作 则是对被匹配的文章执行的操作。 对于每个过滤规则支持多个匹配规则，点击 Add 添加 添加新规则，可以设置匹配的对象和指定订阅源，支持正则表达式。多个匹配规则默认是「与」的关系，如果要改成「或」的话就打开 Match any rule 匹配任意规则 。 而对于被筛选出来的文章也有多种操作，一个特殊的操作是 Publish article ，会被放入 Published articles 已发布的文章 区域。 高级配置###订阅更新 Tiny Tiny RSS 支持两种更新方式：简单更新和定时更新。 简单更新简单更新模式，指每次打开的时候就立即更新。 可以用宝塔面板或者 vi 终端打开网站根目录下的 config.php ，然后定位到 SIMPLE_UPDATE_MODE 并将其改为 true ，即可。 定时更新使用 cron 实现：由于 Tiny Tiny RSS 无法 root 运行，我们不能使用宝塔计划任务。这里要手动添加定时任务。 可以通过一下命令检查是否运行： 如果报错，就检查一下目录是否正确。 P.S. (2020-1-27 更新) 博主用上面的方法不是很成功，换了以下方法： 使用 daemon 配合 systemd 更新 (官方推荐) ：在 /etc/systemd/system/ 创建一个 ttrss.service ，输入： 注意将路径改为自己的。 然后使用命令启动： 查看服务状态： 全文爬取其实 RSS 不受待见的一个原因是它会分走站点的部分流量。所以有些网站放不开手，要么不提供 RSS 订阅，要么订阅后只能看前几行，想看全文还是要打开网页查看。但这样的跳转是很影响体验的，而 Tiny Tiny RSS 也有全文爬取的插件。 安装 mercury_fulltext 插件 定位到插件目录： 安装插件 (Git) ，当然也可以手动下载插件然后放到相应位置 在 Preferences 偏好设置 中启用该插件 搭建 Mercury Parser API项目地址 我们已经在 #准备环境 中安装了 Docker CE ，现在只需要输入： 配置 mercury_fulltext在 Preferences -&gt; Feeds -&gt; Mercury Fulltext settings (mercury_fulltext) 中填入 API 地址 localhost:3000 。 笔者是直接在本机搭建，如果在其他服务器上搭建，就用 host + ip 的形式。 使用右键需要打开此插件的订阅源，点击 编辑信息源 -&gt; 插件 位置打开 mercury_fulltext 插件。 然后再右键该订阅源，点击 调试信息源 ，勾选 force refetch ，然后 continue。 完成后就发现讨厌的 Read more … 没有了！ 平台使用插件：feverTiny Tiny RSS 毕竟还是个小众的框架，需要插件使得第三方服务端适配。 目前比较好的选择仍是 fever ，尽管它已经 3 年没有更新，但是大体不影响使用。 上 GitHub 下载，解压源码 将解压得到的文件夹里的 fever 文件夹上传至插件文件夹 (网站根目录/plugins.local) 在 Preferences 偏好设置中会出现一个新的页面设置独立密码并记录下 RSS 链接。 桌面端：浏览器其实就桌面端而言，浏览器的体验已经很优秀了。如果不满意还可以使用 Theme 主题 ，比如笔者比较喜欢的 Feedly Theme 。可以参照 Readme.md 的使用方法，也可以下载到电脑，解压，然后利用宝塔面板上传到指定位置 (网站根目录/theme.local) ，只用上传 CSS 文件。一个主题有时包含许多个 CSS ，是主题的不同模式 (如暗色模式等) ，大家选择性上传。 然后在 Preferences 偏好设置 -&gt; Theme 主题 中选取一个要使用的 CSS，保存即可。 ####Android: Feedme 安卓上比较推荐一款应用：Feedme，一款 Google Play 上的应用，直接支持导入Tiny Tiny RSS。初次打开的时候可以选择 Tiny Tiny RSS 登录 ，输入网址、用户名、登录密码即可使用。但是需要在偏好设置中打开 启用 API 。 iOS: Reeder / iPadOS: Mr.ReaderiOS／iPadOS 上的应用，采用 fever 独立 RSS 链接和密码使用。 结尾到这里，笔者已经完全交代了直至我自己满意的配置了，并且在融合的过程中，它已经可以很好地替代了之前使用的 Inoreader。 确实，熟练的话半个小时也许就能使用。我却折腾了 2、3 个小时才从各种坑中爬出来。 那么问题来了——值得吗？ 在抖音、头条这些 App 兴起的衬映下，RSS 似乎就显得十分「老套」了。可是这些快资讯平台带来的浅阅读质量实在无法拿捏，而且久而久之还可能丧失独立深度思考的能力。 尽管我对这些 App 保持了距离，但是各类新媒体还是源源不断地冒出来。我空余刷社交媒体、他人博客、各种资讯网站的时间，从半个小时、一个小时到了不久前接近 4 个小时每天。 其实每个人一生能够掌握的信息是极其有限的，也许就几十个 G 。整个 2019 年互联网平均每天产生的数据都有 491EB 这么多，在这种巨大的悬殊下怎么甘心任时间在各种廉价资讯中消磨殆尽。 这回，我把部分高质量感兴趣的网站、博客放进 RSS ，把一些重要的 Telegram 通知频道／Twitter 通过工具也放进 RSS ，设置为 4 个小时更新一次。每天在通勤、午休、晚上定期查阅。也许我获取到的有效信息数量与之前是差不多的，可是现在据数字健康统计，每天花费在这上面的时间压缩至 1.5 个小时左右。这也许能让我有精力去做一些更大块的事情，更有意义的事情…… 所以，我的答案是，肯定的。"},{"title":"IPLC 内网专线机场 | N3ro | 机场推荐","date":"2020-01-14T04:24:40.000Z","url":"/outlook/n3ro/","categories":["分享集"],"content":"这里是 ChrAlpha 的个人博客，并非 N3ro 的推广站。博主仅仅是 N3ro 的众多客户中一员，也仅仅分享一下自己的使用体验，不接广告。希望能给你一个参照。 接触 N3ro 大半年了，从最初 19 年 6 月认识到现在，尽管中途经历一次易主，但荣光依旧。不仅有 IPLC 内网专线看家本领，还有低倍率中继线路性价比加持。只能说确实稳定，站长很走心。从轻量到中、重度皆有选择，速度蛮不错的，打游戏也挺有优势。推荐给有需要的朋友们。 N3ro | IPLC 专线高端机场N3ro一直是我的主力机场。大概是 19 年 5、6 月左右接触到这家机场的，后面有很强的技术支撑，全 IPLC/BGP 专线在各种时期都游刃有余，各种会议全无放假。 IPLC 简介IPLC (International Private Leased Circuit) 即国际专线，是指用户跨国数据通过的专用通道。这样在访问的时候不走普通的大陆公网出口出去，以达到全天候不用过墙，无惧任何会议的目的。但是缺点就是成本较高。 自然 IPLC 的优势就很明显了： 稳定：流量完全不经过审查，理论上不用担心 IP 不可用的情况。而且也避免了审查带来的性能损耗 速度：虽然成本较高，但是由于是两点对接，之间的线路肯定可以专门优化，延迟低且速度快，还是稳定。 N3ro 优势 基于 IPLC 国际专线 的私有线路加持，拥有 IPLC 的所有优势 由于 IPLC 成本较高，绝大多数厂商仅提供重度使用套餐支持，起步较高。N3ro 也是为数不多我了解的提供轻量低起步套餐的厂商，即便是轻量用户也可以以实惠的价格享受 IPLC 带来的极致体验。 全平台服务支持 (iOS/iPadOS、Android、Windows、macOS、Linux) 购买 3 天内可以 无理由退款 (仅限月付)。 测速参考： 部分线路为保证稳定性采用端口限速，不影响正常使用。 购买订阅首先你需要在 N3ro 注册一个账号，不介意的话可以点击笔者的 Referral 。 订阅套餐： 流量加餐包 (可为原套餐增加流量) ： 选择适合自己需求的购买即可。 N3ro Telegram 群组： 中途出现任何付款有关的问题，都可以心平气和礼貌地从 Telegram 找站长 海螺 ，留言即可，人在欧洲，8 个小时的时差。 机场也专门雇人写了 帮助文档 ，不知道如何使用的同学也请尝试求助于文档。 关于流量/耗电的说明关于流量我在这里多说几句。正常日用耗费的流量真的是不多的。另外如果有下载或者刷剧的话，下面有个参考。 12小时的 1080p 视频耗费流量 10G： 7个半小时的 4k 视频耗费流量 50G： 除 IPLC 是 1 倍率外，中继都在 0.25 - 0.35 倍率这个区间，CN2 节点在 0.2 倍率，所以日用应该完全够用的。 倍率：假如倍率为 0.3 ，那么你实际使用 10G 流量，只按照 10G * 0.3 = 3G 来计费。 然后是耗电。我平时梯子是 24 小时不关的，虽然看似耗电很多，但其实这是移动端的一个特殊机制罢了。开启绝大多数梯子客户端后，会接管（几乎）所有的流量，然后再根据规则等判断是否走代理。所以只是这些客户端替其他消耗流量等软件多背了一次锅而已。"},{"title":"Cloudflare Worker 配合 Google Analytics 管理网站流量","date":"2019-12-21T08:46:50.000Z","url":"/post/google-analytics-cooperates-cloudflare-worker-to-manage-your-website-trafic/","tags":["SEO","Analytics","Cloudflare"],"categories":["笔记本"],"content":"笔者一直使用 Google Analytics 分析流量，以助于更好的提供内容。但是由于大多访问量来自国内，Google 国内的数据中心又…… 又于是在浏览 @SukkaW 的博客的时候偶然发现了解决方法，便在这里分享出来，以供大家参考。 Cloudflare Workers 简介官网介绍： Build serverless applications on Cloudflare’s global cloud network spanning 194 cities across over 90 countries. Cloudflare Workers provides a lightweight JavaScript execution environment that allows developers to augment existing applications or create entirely new ones without configuring or maintaining infrastructure. 翻译： 利用 Cloudflare 90 多个国家／194 个城市的全球云网络搭建一个无后端的应用程序。Cloudflare Workers 提供了一个轻量的执行环境，使开发人员无需配置维护基础架构就可以扩展或者构建一个应用程序。 简而言之就是提供轻量级的服务器直接实现一些无后端的服务。 Cloudflare 国内还和百度有合作，光国内就又有 20 余台服务器。我们可以很方便的将用 Cloudflare Workers 来将数据转发至 Google Analytics 。 Cloudflare 依然十分慷慨地给了每日 10 万次的免费请求额度，一般的站点应该都是够的了，这里分享一下如何实现。 使用1. 新建一个 Worker登录进你的 Cloudflare 账号，然后进入 Workers App (Menu -&gt; Workers) 。 然后新建一个 Worker ，删除原来的代码，再加入以下代码。 保存、应用即可。 2. 插入对应 JS 到网站插入以下文本到你的网站的 &lt;/head&gt; 里，注意将默认信息换成是你自己的。 关于 ga_tid 应该不用说，Google Analytics 的 Track ID ，在 [管理 -&gt; 跟踪信息 -&gt; 跟踪代码] 主可以找到。 ga_api 后跟刚刚创建 Worker 的路径，类似 workername.yourname.worker.dev 的形式，可以直接在这获取。 如果你也使用 Hexo ，只需在配置文件的类似 /layout/_partial/ 内会有一个 head 为文件名的文件，在块 &lt;/head&gt; 下加入，在下次 Generate 的时候就会给每个页面添加上那一段代码了。 完成按照上述步骤走下来，不出意料已经可以完成了。 你可以打开监测网站的一个页面，看看 Google Analytics 是否有实时访问记录。 Ended. "},{"title":"jsDelivr | 免费加速图片等网站静态资源","date":"2019-12-01T05:30:14.000Z","url":"/post/use-jsdelivr-speed-up-static-files-visits/","tags":["Free","CDN","jsDelivr"],"categories":["便签格"],"content":"由于一些众所周知的原因，GitHub 在大陆的访问速度一直不是很理想，如果你也像我一样将博客，图床等放在 GitHub 托管的话，很可能会有同学投诉访问速度，特别是初次打开的时候，速度着实堪忧。那有没有什么低成本的方案，来加速我们的网站打开速度呢？当然是有的。 CDN 简介 内容分发网络（英语：Content Delivery Network或Content Distribution Network，缩写：CDN）是指一种透过互联网互相连接的电脑网络系统，利用最靠近每位用户的服务器，更快、更可靠地将音乐、图片、影片、应用程序及其他文件发送给用户，来提供高性能、可扩展性及低成本的网络内容传递给用户。 —— Wikipedia 简而言之就是让服务器距离大陆较远的 GitHub ，将托管在那里的静态资源缓存到一个近一点的服务器，从而加快访问。 看了这样的解释你应该能够理解，CDN 虽然能缓解互联压力，可也是要耗费一定的资源的，从而市面上的 CDN 大多是收费的。Cloudflare 虽然有免费 CDN ，可是国内节点致开放给专业版用户使用，价格偏高，而海外的节点又类似负优化，可能还会降低速度。 jsDelivrjsDelivr 是一款公共免费 CDN ，调用多家 CDN 保证全球服务质量、拥有多层缓存和灾后保障 SLA 100 。也是为数不多的有 ICP 备案，提供许多中国节点的海外 CDN 服务商。 基础使用其实 jsDelivr 的使用非常简单——直接发布个 Release 就能用了。 如托管在 GitHub 的仓库链接都是  的形式，而我们就可以将前面的 github.com 改成 jsDelivr 提供加速 GitHub 仓库的域名 cdn.jsdelivr.net/gh 。 嗯，兴冲冲配置一发，发现什么都没有？其实还是有一点点小差别的。比如分支那里，jsDelivr 默认要直接在仓库名后面 @ ，所以真正其实是  的形式。当然，如果你放在仓库的默认分支，还可以直接将 branch 这个关键字直接删了，变成  一样能获取到！ 另外，如果是一些比较稳定的文件，后面不会频繁地改动，还可以发布成一个版本，然后在 repo 后 @version 就可以引用对应的版本。 加速图床如果你还记得笔者之前写的 PicGo + GitHub 搭建免费图床 的话，不难发现 jsDelivr 也是能加速这个图床（本质不还是一个 GitHub 仓库嘛）的。我们只需要在 GitHub 图床设置 中将链接设置为  即可！前提是你上传到默认分支。 关联阅读：ChrAlpha - PicGo + GitHub 搭建免费图床 尾巴这么好的东西，还是有一点限制的。比如单个文件最大不能超过 20M ，但是不限制流量。这 20M 你甚至能来加速一个小视频…… 其实还可以加速博客的主题配置，js/css 文件，图标，头像等，从而加速博客的访问速度，比如我的博客在加上 CDN 后访问速度一度从 2s 左右降低到 0.8s ，体验自然是上去了。"},{"title":"GitHub + PicGo 免费图床搭建及使用教程","date":"2019-10-20T07:41:38.000Z","url":"/post/free-img-hosting-with-github-and-picgo/","tags":["图床","Free"],"categories":["笔记本"],"content":" PicGo 官方 GitHub 地址 , PicGo 中文文档 主理人说图床，可以理解为让图片「躺好」在互联网上的工具，方便图片在网络上被调用。 如果你也想让图片辅佐内容输出，那么一个得心应手的图床是必不可少的。 如果我们对比一下各路图床： 微博图床添加防盗链，凉凉 SM.MS 运营许久，但是使用的人过多，API 不稳定（曾经被滥用），转付费模式后免费版高峰期访问速度更加堪忧。 Imgur 国外著名免费图床，但国内访问速度实在不尽人意，且有被墙的风险。 小众图床，不是我不相信「小而美」，但是万一跑路了真的很伤。 尝试过的朋友可能知道，图床选定使用过一段时间，想要转移是非常痛苦的。所以早期选好一个稳定、方便的图床确实很有必要。 那究竟有没有免费且效果还不错的图床选择呢？ 当然有！折腾过一番图床，我最后还是选择了 GitHub + PicGo 的方式。 优点： 全免费！ 没有大小限制，也不会对图片自行压缩。 后台稳定，一般不会有莫名其妙的连不上。 如果配合 jsDelivr 免费 CDN 加速缓存，更能收获意想不到的速度体验。 话不多说，赶紧看看如何用上。 使用基本配置首先我们要有一个 GitHub 仓库来放置这些图片。你需要一个 GitHub 账号，常规注册就好。然后新建一个仓库，名字任意，但一定要是公开仓库。 然后在 Github -&gt; Settings -&gt; personal accese token 这里新建一个 token ，打开 repo 权限，然后将显示的 token 复制出来（最好存下来，这个 token 只会出现一次）。 之后在 图床设置 -&gt; GitHub 设置 中把 token 导入进去。 至此已经可以导入了！ 可选：将 GitHub 设为默认图床，这样以后上床的时候就不用再选择。 导入方法 在导入区，把图片拖进去，或者选择文件 右键图片选择 使用 PicGo 导入 如果你使用的是 Mac ，那么运行后在上方的控制条中会有个图标。 直接将图片拖到那个位置就上传了 如果你使用的是 windows ，可以开启一个悬浮窗，将图片拖到悬浮窗即可。 PicGo 配置点击 PicGo 配置 ，可以看到一些关于软件的设置，比如可以选择只将你常用的图床放在侧边栏，或者使用时间戳重命名等（可有效防止重名）。 关联阅读：ChrAlpha - jsDelivr 免费加速静态资源 后PicGo 支持了 Mac, Windows, Linux，是一款开源免费的 electron-app，如果大家觉得好用，可以上 GitHub 去给他们点 star 。"},{"title":"Github Page + Hexo 免费搭建个人博客教程全攻略","date":"2019-10-05T03:34:51.000Z","url":"/post/set-up-your-blog-for-free-with-github-page-and-hexo/","tags":["hexo","自建"],"categories":["笔记本"],"content":"折腾这个个人博客有些时日了，自己也踩了非常多的坑。刚好同学看到我博客后也问我怎么搭的，就借此把这些坑填了。 为什么要写博客？其实写博客并不是为了成为什么作家。 但我们也可以通过写作进入享受反馈良性循环。 不断从外界接受反馈，也能更好的了解自己。 一点关于知识的输入、输出：我们通过导师，书籍 等方式获取到信息，算是知识的输入(从外界获取信息)，而这并不算是 学习 ，学习不仅仅是记忆，更要将其转化，整理成你可以使用的内容，这才算一次学习。（强烈推荐 知乎-学习观系列短片），而许多人学习只是将其“记下来”，并未完成后续的分类、整理等步骤。 人是有惰性的，输出就可以很好的促进你输入，或者提升你输入的质量。 只不过，真正的难点，是坚持。 有些人上来满腔热血，搞了一大堆东西，最后热度一过，就坚持不下来了。 这反而会使你那些前期的努力没有尽到它的价值。 输出 就能很好的激发你。将自己学习或研究的一些结果与他人分享，不仅帮助到他人，更使自己对其的印象深刻，条例清晰。 总之，我还是非常建议大家建立自己的个人博客，找到这么一个属于自己的 输出流 。 对比一下其实除了 GitHub Page ，还可以购买 VPS 来搭建自己的博客，不过国内主机普遍偏贵，国外主机连接速度不一定理想，还会有一些奇怪的事情发生(附带爱国上网？)，再加上国内使用域名都要备案，这些操作非常麻烦。相较之下 GitHub 就没那么容易被墙(参考以前案例)，服务也比较稳定，况且完全免费，学生党也不用纠结！ 三步走本系列教程分两个个片段： 基础搭建篇 链接 主题美化篇 nexT: 链接 (不再维护) material-x: 链接 (持续更新) 大家按需求食用即可"}]